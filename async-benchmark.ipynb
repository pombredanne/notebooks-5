{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import signal\n",
    "import gunicorn.app.base\n",
    "from multiprocessing import Process\n",
    "from contextlib import contextmanager\n",
    "\n",
    "HOST, PORT = \"127.0.0.1\", \"8080\"\n",
    "\n",
    "class BenchmarkApplication(gunicorn.app.base.BaseApplication):\n",
    "\n",
    "    def __init__(self, app, worker_class, threads):\n",
    "        self.worker_class = worker_class\n",
    "        self.threads = threads\n",
    "        self.application = app\n",
    "        super().__init__()\n",
    "\n",
    "    def load_config(self):\n",
    "        self.cfg.set(\"bind\", f\"{HOST}:{PORT}\")\n",
    "        self.cfg.set(\"workers\", 2)\n",
    "        self.cfg.set(\"worker_class\", self.worker_class)\n",
    "        self.cfg.set(\"threads\", self.threads)\n",
    "        \n",
    "    def load(self):\n",
    "        return self.application\n",
    "\n",
    "def run(app, worker, threads):\n",
    "    BenchmarkApplication(app, worker, threads).run()\n",
    "    \n",
    "@contextmanager\n",
    "def app_running(app, worker, threads=1):\n",
    "    p = Process(target=lambda: run(app, worker, threads))\n",
    "    p.start()\n",
    "    time.sleep(1)\n",
    "    print(\"allowed sleep\")\n",
    "    yield \n",
    "    os.kill(p.pid, signal.SIGINT)\n",
    "    print(\"kill sent\")\n",
    "    p.join(timeout=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "from multiprocessing import Process\n",
    "\n",
    "class Stats:\n",
    "    def __init__(self):\n",
    "        self.request_latencies = []\n",
    "        self.timed_out = 0\n",
    "        self.elapsed_time = 0\n",
    "\n",
    "async def fetch(stats, session, url):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        async with session.get(url) as response:\n",
    "            await response.text()\n",
    "    except:\n",
    "        stats.timed_out += 1\n",
    "    else:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        stats.request_latencies.append(elapsed_time)\n",
    "\n",
    "import aiohttp\n",
    "TOTAL_COUNT = 1000\n",
    "MAX_CONNECTIONS = 200\n",
    "\n",
    "async def benchmark(root=\"http://localhost:8080/\"):\n",
    "    url = root + \"foo\"\n",
    "    stats = Stats()\n",
    "    start_time = time.time()\n",
    "    conn = aiohttp.TCPConnector(limit=MAX_CONNECTIONS)\n",
    "    async with aiohttp.ClientSession(connector=conn) as session:\n",
    "        task_list = []\n",
    "        for i in range(TOTAL_COUNT):\n",
    "            task_list.append(fetch(stats, session, url))\n",
    "        await asyncio.gather(*task_list)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    stats.elapsed_time = elapsed_time\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-04 22:08:15 -0700] [922] [INFO] Starting gunicorn 19.7.1\n",
      "[2017-07-04 22:08:15 -0700] [922] [INFO] Listening at: http://127.0.0.1:8080 (922)\n",
      "[2017-07-04 22:08:15 -0700] [922] [INFO] Using worker: aiohttp.worker.GunicornWebWorker\n",
      "[2017-07-04 22:08:15 -0700] [929] [INFO] Booting worker with pid: 929\n",
      "[2017-07-04 22:08:16 -0700] [932] [INFO] Booting worker with pid: 932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allowed sleep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-04 22:08:53 -0700] [922] [INFO] Handling signal: int\n",
      "[2017-07-04 22:08:53 -0700] [929] [INFO] Stopping server: 929, connections: 0\n",
      "[2017-07-04 22:08:53 -0700] [932] [INFO] Stopping server: 932, connections: 0\n",
      "[2017-07-04 22:08:53 -0700] [929] [INFO] Worker exiting (pid: 929)\n",
      "[2017-07-04 22:08:53 -0700] [932] [INFO] Worker exiting (pid: 932)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-04 22:08:53 -0700] [922] [INFO] Shutting down: Master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.453277587890625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 464.,   67.,   77.,   91.,   72.,   45.,   35.,   40.,   45.,\n",
       "          41.,    1.,    0.,    0.,    0.,    0.,    0.,    2.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    2.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    2.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    2.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    2.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    2.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    2.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    2.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    2.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    2.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    2.]),\n",
       " array([  0.36441493,   0.72453927,   1.0846636 ,   1.44478794,\n",
       "          1.80491227,   2.16503661,   2.52516094,   2.88528528,\n",
       "          3.24540961,   3.60553395,   3.96565828,   4.32578262,\n",
       "          4.68590695,   5.04603129,   5.40615562,   5.76627996,\n",
       "          6.12640429,   6.48652863,   6.84665297,   7.2067773 ,\n",
       "          7.56690164,   7.92702597,   8.28715031,   8.64727464,\n",
       "          9.00739898,   9.36752331,   9.72764765,  10.08777198,\n",
       "         10.44789632,  10.80802065,  11.16814499,  11.52826932,\n",
       "         11.88839366,  12.24851799,  12.60864233,  12.96876667,\n",
       "         13.328891  ,  13.68901534,  14.04913967,  14.40926401,\n",
       "         14.76938834,  15.12951268,  15.48963701,  15.84976135,\n",
       "         16.20988568,  16.57001002,  16.93013435,  17.29025869,\n",
       "         17.65038302,  18.01050736,  18.37063169,  18.73075603,\n",
       "         19.09088037,  19.4510047 ,  19.81112904,  20.17125337,\n",
       "         20.53137771,  20.89150204,  21.25162638,  21.61175071,\n",
       "         21.97187505,  22.33199938,  22.69212372,  23.05224805,\n",
       "         23.41237239,  23.77249672,  24.13262106,  24.49274539,\n",
       "         24.85286973,  25.21299407,  25.5731184 ,  25.93324274,\n",
       "         26.29336707,  26.65349141,  27.01361574,  27.37374008,\n",
       "         27.73386441,  28.09398875,  28.45411308,  28.81423742,\n",
       "         29.17436175,  29.53448609,  29.89461042,  30.25473476,\n",
       "         30.61485909,  30.97498343,  31.33510777,  31.6952321 ,\n",
       "         32.05535644,  32.41548077,  32.77560511,  33.13572944,\n",
       "         33.49585378,  33.85597811,  34.21610245,  34.57622678,\n",
       "         34.93635112,  35.29647545,  35.65659979,  36.01672412,  36.37684846]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad518e04a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from aiohttp import web\n",
    "import asyncio\n",
    "\n",
    "async def handle(request):\n",
    "    name = request.match_info.get('name', \"Anonymous\")\n",
    "    await asyncio.sleep(0.1)\n",
    "    text = \"Hello, \" + name\n",
    "    return web.Response(text=text)\n",
    "\n",
    "aiohttp_app = web.Application()\n",
    "aiohttp_app.router.add_get('/', handle)\n",
    "aiohttp_app.router.add_get('/{name}', handle)\n",
    "    \n",
    "import asyncio\n",
    "loop = asyncio.get_event_loop()\n",
    "with app_running(aiohttp_app, \"aiohttp.worker.GunicornWebWorker\"):\n",
    "     stats = loop.run_until_complete(benchmark())\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(stats.elapsed_time)\n",
    "plt.hist(stats.request_latencies, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "flask_app = Flask(__name__)\n",
    "import time\n",
    "\n",
    "@flask_app.route(\"/<name>\")\n",
    "def hello(name):\n",
    "    time.sleep(0.1)\n",
    "    return \"Hello World!\"\n",
    "\n",
    "import asyncio\n",
    "loop = asyncio.get_event_loop()\n",
    "with app_running(flask_app, \"sync\", threads=10):\n",
    "    stats = loop.run_until_complete(benchmark())\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(stats.elapsed_time)\n",
    "plt.hist(stats.request_latencies, bins=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
